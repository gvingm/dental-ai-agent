import streamlit as st
import os
import json
from langchain_openai import ChatOpenAI
from langchain_community.utilities import GoogleSerperAPIWrapper
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# === –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–ù–ò–¶–´ ===
st.set_page_config(page_title="AI Sales Demo", page_icon="ü¶∑")
st.title("ü¶∑ AI Dental Sales Agent")
st.markdown("Automated Lead Gen -> Sales Call -> CRM Entry")

# === SIDEBAR (–ö–õ–Æ–ß–ò) ===
DEFAULT_OPENAI = "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"
DEFAULT_SERPER = "b077a66ea2e5e669cdb8934381d81e9be2f5d59b"

with st.sidebar:
    st.header("Settings")
    if "openai_key" not in st.session_state:
        st.session_state["openai_key"] = DEFAULT_OPENAI
    if "serper_key" not in st.session_state:
        st.session_state["serper_key"] = DEFAULT_SERPER
        
    openai_key = st.text_input("OpenAI Key", value=st.session_state["openai_key"], type="password")
    serper_key = st.text_input("Serper Key", value=st.session_state["serper_key"], type="password")
    
    if st.button("Save & Apply"):
        st.session_state["openai_key"] = openai_key
        st.session_state["serper_key"] = serper_key
        os.environ["OPENAI_API_KEY"] = openai_key
        os.environ["SERPER_API_KEY"] = serper_key
        st.success("Keys Saved!")

if not os.environ.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = st.session_state.get("openai_key", DEFAULT_OPENAI)
    
if not os.environ.get("SERPER_API_KEY"):
    os.environ["SERPER_API_KEY"] = st.session_state.get("serper_key", DEFAULT_SERPER)

# === –õ–û–ì–ò–ö–ê (–§–£–ù–ö–¶–ò–ò) ===

def get_llm():
    return ChatOpenAI(
        model="openai/gpt-4o",
        base_url="https://openrouter.ai/api/v1",
    	api_key=os.environ["OPENAI_API_KEY"],
        temperature=0
    )

def simulate_call(clinic_name, clinic_price):
    llm = get_llm()
    history = []
    transcript = []

    admin_sys = SystemMessage(content=f"You are ADMIN at '{clinic_name}'. Price: {clinic_price}. Goal: Book appointment. Language: Russian. Start with 'ADMIN:'.")
    client_sys = SystemMessage(content=f"You are CLIENT. Found price {clinic_price}. Verify it. Language: Russian. Start with 'CLIENT:'.")
    
    history.append(admin_sys)
    
    steps = [
        "Start call. Ask about price.",
        f"Admin said: '{{prev}}'. Ask why so cheap.",
        "Say: 'Ok, book me for tomorrow'."
    ]
    
    msg1 = llm.invoke([client_sys, HumanMessage(content=steps[0])])
    text1 = msg1.content.replace("CLIENT:", "").strip()
    transcript.append(f"üë§ **–ö–õ–ò–ï–ù–¢:** {text1}")
    history.append(HumanMessage(content=f"CLIENT: {text1}"))
    
    msg2 = llm.invoke(history)
    text2 = msg2.content.replace("ADMIN:", "").strip()
    transcript.append(f"üë©‚Äç‚öïÔ∏è **–ê–î–ú–ò–ù:** {text2}")
    history.append(SystemMessage(content=f"ADMIN: {text2}"))
    
    msg3 = llm.invoke([client_sys, HumanMessage(content=steps[1].format(prev=text2))])
    text3 = msg3.content.replace("CLIENT:", "").strip()
    transcript.append(f"üë§ **–ö–õ–ò–ï–ù–¢:** {text3}")
    history.append(HumanMessage(content=f"CLIENT: {text3}"))
    
    msg4 = llm.invoke(history)
    text4 = msg4.content.replace("ADMIN:", "").strip()
    transcript.append(f"üë©‚Äç‚öïÔ∏è **–ê–î–ú–ò–ù:** {text4}")
    history.append(SystemMessage(content=f"ADMIN: {text4}"))
    
    msg5 = llm.invoke([client_sys, HumanMessage(content=steps[2])])
    text5 = msg5.content.replace("CLIENT:", "").strip()
    transcript.append(f"üë§ **–ö–õ–ò–ï–ù–¢:** {text5}")
    
    msg6 = llm.invoke(history + [HumanMessage(content=f"CLIENT: {text5}")])
    text6 = msg6.content.replace("ADMIN:", "").strip()
    transcript.append(f"üë©‚Äç‚öïÔ∏è **–ê–î–ú–ò–ù:** {text6}")

    return transcript

def analyze_crm(transcript_list):
    llm = get_llm()
    text = "\n".join(transcript_list)
    crm_template = """
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥. –í–µ—Ä–Ω–∏ JSON —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:
    {{
      "—Å—Ç–∞—Ç—É—Å": "...",  # –ù–∞–ø—Ä–∏–º–µ—Ä, "–∑–∞–ø—Ä–æ—Å", "–∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–æ", "–æ—Ç–∫–∞–∑"
      "—Ü–µ–Ω–∞_—É–ø–æ–º—è–Ω—É—Ç–∞": "...", # –ù–∞–ø—Ä–∏–º–µ—Ä, "10000 —Ä—É–±" –∏–ª–∏ "–Ω–µ —É–∫–∞–∑–∞–Ω–∞"
      "—Ä–µ–∑—É–ª—å—Ç–∞—Ç_–∑–≤–æ–Ω–∫–∞": "..." # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    }}
    –¢–µ–∫—Å—Ç: {t}
    """
    chain = ChatPromptTemplate.from_template(crm_template) | llm | StrOutputParser()
    raw_response = chain.invoke({"t": text})

    try:
        clean_json_str = raw_response.strip().replace("```json", "").replace("```", "").strip()
        return json.loads(clean_json_str)
    except json.JSONDecodeError:
        return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å JSON –æ—Ç LLM", "raw_response": raw_response}


def search_cheapest_clinic(query):
    search = GoogleSerperAPIWrapper()
    try:
        raw_results = search.results(query)
        organic = raw_results.get("organic", [])
    except Exception as e:
        return None, None, f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ Google: {str(e)}"
    
    if not organic:
        return None, None, "–í Google –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

    text_data = ""
    for item in organic:
        text_data += f"–ö–ª–∏–Ω–∏–∫–∞: {item.get('title')}\n–û–ø–∏—Å–∞–Ω–∏–µ: {item.get('snippet')}\n\n"
        
    analyst_template = """
    –¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–π—Ç–∏ —Å–∞–º—É—é –Ω–∏–∑–∫—É—é —Ü–µ–Ω—É –Ω–∞ –∏–º–ø–ª–∞–Ω—Ç–∞—Ü–∏—é (—Å–≤—ã—à–µ 10000 —Ä—É–±).
    –¢–µ–∫—Å—Ç –ø–æ–∏—Å–∫–∞:
    {text}
    
    –ï—Å–ª–∏ –Ω–∞—à–µ–ª, –≤–µ—Ä–Ω–∏ –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –ù–∞–∑–≤–∞–Ω–∏–µ|–¶–µ–Ω–∞
    –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–µ–ª —Ü–µ–Ω—É, –ø—Ä–∏–¥—É–º–∞–π —Å—Ä–µ–¥–Ω—é—é –ø–æ —Ä—ã–Ω–∫—É, –Ω–æ —Ñ–æ—Ä–º–∞—Ç —Å–æ—Ö—Ä–∞–Ω–∏: –°—Ä–µ–¥–Ω—è—è –ö–ª–∏–Ω–∏–∫–∞|25000 —Ä—É–±
    –ù–µ –ø–∏—à–∏ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤. –¢–æ–ª—å–∫–æ: –ù–∞–∑–≤–∞–Ω–∏–µ|–¶–µ–Ω–∞
    """
    
    llm = get_llm()
    chain = ChatPromptTemplate.from_template(analyst_template) | llm | StrOutputParser()
    
    try:
        res = chain.invoke({"text": text_data}).strip()
        
        if "|" in res:
            parts = res.split("|")
            name = parts[0].strip()
            price = parts[1].strip() if len(parts) > 1 else "–¶–µ–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É"
        else:
            parts = res.split()
            if len(parts) > 1:
                price = parts[-1]
                name = " ".join(parts[:-1])
            else:
                name = res
                price = "–£—Ç–æ—á–Ω—è–π—Ç–µ"
                
        return name, price, None
        
    except Exception as e:
        return None, None, f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ LLM: {str(e)}"

# === –ò–ù–¢–ï–†–§–ï–ô–° ===

query = st.text_input("Search Query", "—Å—Ç–æ–º–∞—Ç–æ–ª–æ–≥–∏—è –ú—É—Ä–∏–Ω–æ –∏–º–ø–ª–∞–Ω—Ç–∞—Ü–∏—è —Ü–µ–Ω–∞")

if st.button("üöÄ Start AI Agent"):
    with st.status("ü§ñ AI Agent Working...", expanded=True) as status:
        
        st.write("üîç –ü–æ–∏—Å–∫ –ª—É—á—à–µ–π —Ü–µ–Ω—ã –≤ Google...")
        name, price, err = search_cheapest_clinic(query)
        
        if err:
            st.error(f"–û—à–∏–±–∫–∞: {err}")
            status.update(label="–ù–µ—É–¥–∞—á–∞", state="error")
        else:
            st.success(f"–ù–∞–π–¥–µ–Ω–æ: **{name}** –ø–æ —Ü–µ–Ω–µ **{price}**")
            
            st.write("üìû –°–∏–º—É–ª–∏—Ä—É—é –∑–≤–æ–Ω–æ–∫...")
            transcript = simulate_call(name, price)
            for line in transcript:
                st.write(line)
            
            st.write("üìä –ó–∞–ø–∏—Å—ã–≤–∞—é –≤ CRM...")
            crm_data = analyze_crm(transcript)
            st.json(crm_data)
            
            status.update(label="–ó–∞–≤–µ—Ä—à–µ–Ω–æ!", state="complete")